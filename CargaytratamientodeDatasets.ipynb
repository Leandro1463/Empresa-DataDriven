{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "#localidades = pd.read_csv(\"DS-PI-ProyectoIndividual\\Datasets\\Localidades.csv\",delimiter = ',',encoding = \"utf-8\")\n",
    "#clientes = pd.read_csv(\"DS-PI-ProyectoIndividual\\Datasets\\Clientes.csv\",delimiter = ';',encoding = \"utf-8\")\n",
    "#clientes = pd.read_csv(\"DS-PI-ProyectoIndividual\\Datasets\\Clientes.csv\",encoding = \"utf-8\",delimiter = ';', usecols=[\"ID\",\"Provincia\",\"Nombre_y_Apellido\",\"Domicilio\",\"Telefono\",\"Edad\",\"Localidad\",\"X\",\"Y\",\"col10\"])\n",
    "#proveedores = pd.read_csv(\"DS-PI-ProyectoIndividual\\Datasets\\Proveedores.csv\",delimiter = ',',encoding = \"ansi\")\n",
    "gasto = pd.read_csv(\"DS-PI-ProyectoIndividual\\Datasets\\Gasto.csv\",delimiter = ',',encoding = \"utf-8\")\n",
    "#compra = pd.read_csv(\"DS-PI-ProyectoIndividual\\Datasets\\Compra.csv\",delimiter = ',',encoding = \"utf-8\")\n",
    "sucursales = pd.read_csv(\"DS-PI-ProyectoIndividual\\Datasets\\Sucursales.csv\",delimiter = ';',encoding = \"utf-8\")\n",
    "#venta = pd.read_csv(\"DS-PI-ProyectoIndividual\\Datasets\\Venta.csv\",delimiter = ',',encoding = \"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CARGA Y TRATAMIENTO DE TABLA VENTAS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargadeVentas():\n",
    "    #ds_path= pathlib.Path(\"Datasets\")\n",
    "    #print(ds_path)\n",
    "    df_list=[]\n",
    "    #archivo=glob.glob('.csv')\n",
    "    #print(\"Hola\")\n",
    "    for file in glob.glob('Vent*.csv'):\n",
    "        #print(file)\n",
    "        df=pd.read_csv(file,delimiter = ',',encoding = \"utf-8\")\n",
    "        df_list.append(df)\n",
    "    venta=pd.concat(df_list)\n",
    "    #Tratamiento de Outliers de Precio \n",
    "    Q1 = venta[\"Precio\"].quantile(0.25)\n",
    "    Q3 = venta[\"Precio\"].quantile(0.75)\n",
    "    #Se calcula el rango intercuartilico IQR.\n",
    "    IQR = Q3 -Q1\n",
    "    outliersSup = (Q3 + (1.5*IQR)) \n",
    "    mask = venta[\"Precio\"]<outliersSup\n",
    "    ventaSinOut2 = venta[mask]\n",
    "    #Creo columnar de Outliers\n",
    "    venta[\"Outlier\"]=np.ones(venta.shape[0])\n",
    "    #Marco Outliers\n",
    "    venta[\"Outlier\"].loc[(venta['Precio'] >= outliersSup)] = 0\n",
    "    #Se crea tabla con precio prodemio por tipo de producto\n",
    "    Precio_Producto= ventaSinOut2.groupby([\"IdProducto\"])[\"Precio\"].mean().reset_index()\n",
    "    Precio_Producto\n",
    "    venta2=venta.copy()\n",
    "    #Reemplazamos valores nulos en Precio y Cantidad\n",
    "    venta2.Precio.fillna(0, inplace=True)\n",
    "    venta2.Cantidad.fillna(1, inplace=True)\n",
    "    Precio_Producto= Precio_Producto.rename(columns= {\"Precio\":\"Precio2\"})\n",
    "    #Agregamos columna auxiliar para obtener valor medio por tipo de producto \n",
    "    venta2 = pd.merge(venta2,Precio_Producto, how=\"left\", on=[\"IdProducto\"])\n",
    "    #Ordeno por IdDeVenta\n",
    "    venta2.sort_values(\"IdVenta\")\n",
    "    #Reemplazamos ventas con precio 0 u Outliers con precios promedio de tipo de producto\n",
    "    #venta2[\"Precio\"]=venta2.apply(lambda x: x[\"Precio2\"] if x[\"Precio\"]==0  else x[\"Precio\"], axis=1)\n",
    "    for i in range(0,venta2.shape[0]):\n",
    "        if venta2.Precio[i] == 0 or venta2.Precio[i]>outliersSup:\n",
    "            venta2.iloc[i,8]=venta2.iloc[i,11] # 8 es precio, 10 es precio 2\n",
    "    venta2.drop(columns=\"Precio2\", inplace=True)\n",
    "    #Tratamiento de Outlier de Cantidad \n",
    "    Q1 = venta2[\"Cantidad\"].quantile(0.25)\n",
    "    Q3 = venta2[\"Cantidad\"].quantile(0.75)\n",
    "    #Se calcula el rango intercuartilico IQR.\n",
    "    IQR = Q3 -Q1\n",
    "    outliersSup = (Q3 + (1.5*IQR)) \n",
    "    mask = venta2[\"Cantidad\"]<outliersSup\n",
    "    ventaCantSinOut = venta2[mask]\n",
    "    cantidadMedia = round(ventaCantSinOut.Cantidad.mean())\n",
    "    venta2.loc[(venta2['Cantidad'] >= outliersSup),\"Cantidad\"] = cantidadMedia\n",
    "    #Se crea columna de Monto de Venta\n",
    "    venta2[\"Monto\"]= venta2[\"Precio\"] * venta2[\"Cantidad\"]*venta2[\"Outlier\"]\n",
    "    venta2.to_csv (r'C:\\Users\\andre\\OneDrive\\Escritorio\\TP Individual N1\\DS-PI-ProyectoIndividual\\datasetsProcesados\\ventas_dataframe.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_10940\\1203019098.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  venta[\"Outlier\"].loc[(venta['Precio'] >= outliersSup)] = 0\n"
     ]
    }
   ],
   "source": [
    "cargadeVentas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CARGA Y TRATAMIENTO DE TABLA COMPRAS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargadeCompras():\n",
    "    #ds_path= pathlib.Path(\"Datasets\")\n",
    "    #print(ds_path)\n",
    "    df_list=[]\n",
    "    #archivo=glob.glob('.csv')\n",
    "    #print(\"Hola\")\n",
    "    for file in glob.glob('Compra.csv'):\n",
    "        #print(file)\n",
    "        df=pd.read_csv(file,delimiter = ',',encoding = \"utf-8\")\n",
    "        df_list.append(df)\n",
    "    compra=pd.concat(df_list)\n",
    "    Q1 = compra[\"Precio\"].quantile(0.25)\n",
    "    Q3 = compra[\"Precio\"].quantile(0.75)\n",
    "    #Se calcula el rango intercuartilico IQR.\n",
    "    IQR = Q3 -Q1\n",
    "    outliersSup = (Q3 + (1.5*IQR)) \n",
    "\n",
    "    mask = compra[\"Precio\"]<outliersSup\n",
    "    compraSinOut2 = compra[mask]\n",
    "\n",
    "    Precio_Producto= compraSinOut2.groupby([\"IdProducto\"])[\"Precio\"].mean().reset_index()\n",
    "    Precio_Producto= Precio_Producto.rename(columns= {\"Precio\":\"Precio2\"})\n",
    "\n",
    "    compra2=compra.copy()\n",
    "    compra2 = pd.merge(compra2,Precio_Producto, how=\"left\", on=[\"IdProducto\"])\n",
    "    compra2.sort_values(\"IdCompra\")\n",
    "\n",
    "    #se reemplazan los 0 de precio2 por el valor de la media de los precios sin outliers.\n",
    "    compra2.Precio2.fillna(compraSinOut2.Precio.mean(),inplace=True)\n",
    "\n",
    "    #se reemplazan los nan por 0 en la columna precio.\n",
    "    compra2.Precio.fillna(0,inplace=True)\n",
    "    #se insertan 1 cuando la cantidad es 0.\n",
    "    compra2.Cantidad.fillna(1,inplace=True)\n",
    "    #Se crea una columna con unos (1) \n",
    "    compra2[\"Outliers\"]=np.ones(compra2.shape[0])\n",
    "    #se marcan con 0 las filas que son outlaiers, para luego ser reemplazadas por Precio2\n",
    "    compra2.loc[(compra2['Precio'] >= outliersSup),\"Outliers\"] = 0\n",
    "\n",
    "    #Este bucle reemplaza los ceros y outliers por los valores promedios \n",
    "    for i in range(0,compra2.shape[0]):\n",
    "      if compra2.Precio[i] == 0 or compra2.Precio[i]>outliersSup:\n",
    "        compra2.iloc[i,7]=compra2.iloc[i,9] # 7 es precio, 9 es precio 2\n",
    "        \n",
    "    #se elimina la columna Precio2\n",
    "    compra2.drop(columns=\"Precio2\", inplace=True)\n",
    "    #Se crea la columna Total\n",
    "    #compra2[\"Total\"]= compra2[\"Precio\"]*compra2[\"Cantidad\"]\n",
    "    #Se calcula el rango intercuartilico IQR.\n",
    "    Q1 = compra2[\"Cantidad\"].quantile(0.25)\n",
    "    Q3 = compra2[\"Cantidad\"].quantile(0.75)\n",
    "    IQR = Q3 -Q1\n",
    "    outliersSup = (Q3 + (1.5*IQR)) \n",
    "    # se crea un df sin outliers, se calcula la media de compras,y se imputan como valor en los casos que sean outliers.\n",
    "    mask = compra2[\"Cantidad\"]<outliersSup\n",
    "    compraCantSinOut = compra[mask]\n",
    "    cantidadMedia = round(compraCantSinOut.Cantidad.mean())\n",
    "    compra2.loc[(compra2['Cantidad'] >= outliersSup),\"Cantidad\"] = cantidadMedia #8\n",
    "    compra2[\"Total\"]= compra2[\"Precio\"]*compra2[\"Cantidad\"]\n",
    "    compra2.to_csv (r'C:\\Users\\andre\\OneDrive\\Escritorio\\TP Individual N1\\DS-PI-ProyectoIndividual\\datasetsProcesados\\compras_dataframe.csv', index = False, header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "cargadeCompras()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CARGA Y TRATAMIENTO DE CLIENTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargadeLocalidades():\n",
    "    #ds_path= pathlib.Path(\"Datasets\")\n",
    "    #print(ds_path)\n",
    "    df_list=[]\n",
    "    #archivo=glob.glob('.csv')\n",
    "    #print(\"Hola\")\n",
    "    for file in glob.glob('Localidades.csv'):\n",
    "        #print(file)\n",
    "        df=pd.read_csv(file,delimiter = ',',encoding = \"utf-8\")\n",
    "        df_list.append(df)\n",
    "    global localidades\n",
    "    \n",
    "    localidades=pd.concat(df_list)\n",
    "\n",
    "    localidades[\"nombre\"]=localidades.apply(lambda x: \"Ciudad de Buenos Aires\" if x[\"municipio_nombre\"]==\"Capital Federal\"  else x[\"nombre\"], axis=1)\n",
    "    localidades.drop(['categoria','fuente', 'localidad_censal_id', 'localidad_censal_nombre', 'municipio_id', 'municipio_nombre' ], axis = 'columns', inplace=True)\n",
    "    localidades[\"departamento_id\"].fillna(\"Sin datos\", inplace=True)\n",
    "    localidades[\"departamento_nombre\"].fillna(\"Sin datos\", inplace=True)\n",
    "    localidades= localidades.rename(columns= {\"centroide_lat\":\"Latitud\"})\n",
    "    localidades= localidades.rename(columns= {\"centroide_lon\":\"Longitud\"})\n",
    "    localidades_repetidas =localidades.id.value_counts()\n",
    "    localidades_repetidas[localidades_repetidas>1]\n",
    "\n",
    "    #Creacion de df Provincia\n",
    "    provincias = pd.DataFrame()\n",
    "    provincias[\"Provincia\"] = localidades.provincia_nombre\n",
    "    provincias[\"IdProvincia\"]=localidades.provincia_id\n",
    "\n",
    "    provincias= provincias.drop_duplicates()\n",
    "    departamentos= pd.DataFrame()\n",
    "    departamentos[\"departamento_nombre\"] = localidades.departamento_nombre\n",
    "    departamentos[\"departamento_id\"]=localidades.departamento_id\n",
    "    departamentos= departamentos.rename(columns= {\"departamento_id\":\"IdDepartamento\",\"departamento_nombre\":\"Departamento\"})\n",
    "    departamentos= departamentos.drop_duplicates()\n",
    "    localidades.drop(columns=\"departamento_nombre\", inplace=True)\n",
    "\n",
    "\n",
    "    localidades= localidades.rename(columns= {\"provincia_nombre\":\"Provincia\"})\n",
    "    localidades[\"nombre\"]= localidades[\"nombre\"].str.title()\n",
    "    localidades[\"Provincia\"]= localidades[\"Provincia\"].str.title()\n",
    "    localidades= localidades.rename(columns= {\"id\":\"IdLocalidad\", \"nombre\":\"Localidad\",\"provincia_id\":\"IdProvincia\", \"departamento_id\":\"IdDepartamento\"})\n",
    "\n",
    "    #Borroduplicados\n",
    "    localidades.drop_duplicates(subset=[\"Localidad\",\"IdProvincia\"], inplace=True)\n",
    "    localidades.reset_index(inplace=True)\n",
    "    \n",
    "    localidades[\"Provincia\"]=[x.replace('á',\"a\") for x in localidades[\"Provincia\"]]\n",
    "    localidades[\"Provincia\"]=[x.replace('é',\"e\") for x in localidades[\"Provincia\"]]\n",
    "    localidades[\"Provincia\"]=[x.replace('í',\"i\") for x in localidades[\"Provincia\"]]\n",
    "    localidades[\"Provincia\"]=[x.replace('ó',\"o\") for x in localidades[\"Provincia\"]]\n",
    "    localidades[\"Provincia\"]=[x.replace('ú',\"u\") for x in localidades[\"Provincia\"]]\n",
    "    localidades[\"Localidad\"]=[x.replace('á',\"a\") for x in localidades[\"Localidad\"]]\n",
    "    localidades[\"Localidad\"]=[x.replace('é',\"e\") for x in localidades[\"Localidad\"]]\n",
    "    localidades[\"Localidad\"]=[x.replace('í',\"i\") for x in localidades[\"Localidad\"]]\n",
    "    localidades[\"Localidad\"]=[x.replace('ó',\"o\") for x in localidades[\"Localidad\"]]\n",
    "    localidades[\"Localidad\"]=[x.replace('ú',\"u\") for x in localidades[\"Localidad\"]]\n",
    "    \n",
    "    \n",
    "    localidades=localidades.append({'Latitud' : 0 , 'Longitud' : 0, 'IdLocalidad' : 0, 'Localidad':\"Sin Datos\",\"Provincia\":\"Sin Datos\"} , ignore_index=True)\n",
    "    localidades.to_csv (r'C:\\Users\\andre\\OneDrive\\Escritorio\\TP Individual N1\\DS-PI-ProyectoIndividual\\datasetsProcesados\\localidades_dataframe.csv', index = False, header=True)\n",
    "    provincias.to_csv (r'C:\\Users\\andre\\OneDrive\\Escritorio\\TP Individual N1\\DS-PI-ProyectoIndividual\\datasetsProcesados\\provincias_dataframe.csv', index = False, header=True)\n",
    "    departamentos.to_csv (r'C:\\Users\\andre\\OneDrive\\Escritorio\\TP Individual N1\\DS-PI-ProyectoIndividual\\datasetsProcesados\\departamentos_dataframe.csv', index = False, header=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_10940\\661035760.py:57: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  localidades=localidades.append({'Latitud' : 0 , 'Longitud' : 0, 'IdLocalidad' : 0, 'Localidad':\"Sin Datos\",\"Provincia\":\"Sin Datos\"} , ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "cargadeLocalidades()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CARGA Y TRATAMIENTO DE CLIENTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cargadeClientes():\n",
    "    #ds_path= pathlib.Path(\"Datasets\")\n",
    "    #print(ds_path)\n",
    "    df_list=[]\n",
    "    #archivo=glob.glob('.csv')\n",
    "    #print(\"Hola\")\n",
    "    for file in glob.glob('Client*.csv'):\n",
    "        #print(file)\n",
    "        df=pd.read_csv(file,delimiter = ';',encoding = \"utf-8\", usecols=[\"ID\",\"Provincia\",\"Nombre_y_Apellido\",\"Domicilio\",\"Telefono\",\"Edad\",\"Localidad\",\"X\",\"Y\",\"col10\"])\n",
    "        df_list.append(df)\n",
    "    clientes=pd.concat(df_list)\n",
    "    clientes.drop(columns=\"col10\", inplace=True)\n",
    "    #Se corrigen nombre de Columnas \n",
    "    clientes= clientes.rename(columns= {\"ID\":\"IdCliente\"})\n",
    "    clientes= clientes.rename(columns= {\"X\":\"Longitud\"})\n",
    "    clientes= clientes.rename(columns= {\"Y\":\"Latitud\"})\n",
    "\n",
    "    #Letra capital\n",
    "    clientes[\"Nombre_y_Apellido\"]= clientes[\"Nombre_y_Apellido\"].str.title()\n",
    "    clientes[\"Domicilio\"]= clientes[\"Domicilio\"].str.title()\n",
    "    clientes[\"Localidad\"]= clientes[\"Localidad\"].str.title()\n",
    "\n",
    "    #Reemplazo de datos faltantes\n",
    "    clientes.Provincia.fillna(\"Sin Datos\", inplace=True)\n",
    "    clientes.Nombre_y_Apellido.fillna(\"Sin Datos\", inplace=True)\n",
    "    clientes.Localidad.fillna(\"Sin Datos\", inplace=True)\n",
    "\n",
    "    clientes.Telefono.fillna(\"Sin Datos\", inplace=True)\n",
    "    clientes.Domicilio.fillna(\"Sin Datos\", inplace=True)\n",
    "\n",
    "    #Reemplazo , por . \n",
    "    clientes[\"Latitud\"] = clientes[\"Latitud\"].str.replace(\",\", \".\")\n",
    "    clientes[\"Longitud\"] = clientes[\"Longitud\"].str.replace(\",\", \".\")\n",
    "\n",
    "\n",
    "    #Reemplazo Latitud y Longitud nulos  con 0\n",
    "    clientes.Latitud.fillna(0.0, inplace=True)\n",
    "    clientes.Longitud.fillna(0.0, inplace=True)\n",
    "    #Normalizo provincia de Buenos Aires \n",
    "    clientes[\"Provincia\"]=clientes.apply(lambda x: \"Buenos Aires\" if x[\"Provincia\"]==\"Ciudad de Buenos Aires\"  else x[\"Provincia\"], axis=1)\n",
    "    #Tratamiendo de acentos \n",
    "    clientes[\"Provincia\"]=[x.replace('á',\"a\") for x in clientes[\"Provincia\"]]\n",
    "    clientes[\"Provincia\"]=[x.replace('é',\"e\") for x in clientes[\"Provincia\"]]\n",
    "    clientes[\"Provincia\"]=[x.replace('í',\"i\") for x in clientes[\"Provincia\"]]\n",
    "    clientes[\"Provincia\"]=[x.replace('ó',\"o\") for x in clientes[\"Provincia\"]]\n",
    "    clientes[\"Provincia\"]=[x.replace('ú',\"u\") for x in clientes[\"Provincia\"]]\n",
    "    clientes[\"Localidad\"]=[x.replace('á',\"a\") for x in clientes[\"Localidad\"]]\n",
    "    clientes[\"Localidad\"]=[x.replace('é',\"e\") for x in clientes[\"Localidad\"]]\n",
    "    clientes[\"Localidad\"]=[x.replace('í',\"i\") for x in clientes[\"Localidad\"]]\n",
    "    clientes[\"Localidad\"]=[x.replace('ó',\"o\") for x in clientes[\"Localidad\"]]\n",
    "    clientes[\"Localidad\"]=[x.replace('ú',\"u\") for x in clientes[\"Localidad\"]]\n",
    "    #Merge entre df Localidades y Clientes para traer dato IdLocalidad a Clientes \n",
    "    clientes = pd.merge(clientes,localidades, how=\"left\", on=[\"Provincia\",\"Localidad\"])\n",
    "\n",
    "    #Reemplazo Latitud y Longitud sin datos con Latitud y Longitud de tabla Localidades \n",
    "    clientes[\"Longitud_x\"]=clientes.apply(lambda x: x[\"Longitud_y\"] if x[\"Longitud_x\"]==0  else x[\"Longitud_x\"], axis=1)\n",
    "    clientes[\"Latitud_x\"]=clientes.apply(lambda x: x[\"Latitud_y\"] if x[\"Latitud_x\"]==0  else x[\"Latitud_x\"], axis=1)\n",
    "    #Renombro columnas\n",
    "    clientes= clientes.rename(columns= {\"Longitud_x\":\"Longitud\"})\n",
    "    clientes= clientes.rename(columns= {\"Latitud_x\":\"Latitud\"})\n",
    "\n",
    "    #Cambio de tipo de dato de Latitud y Longitud\n",
    "    clientes[\"Latitud\"]= clientes.Latitud.astype(float)\n",
    "    clientes[\"Longitud\"]= clientes.Longitud.astype(float)\n",
    "    #Elimino columnas que se agregaron en el merge\n",
    "    clientes.drop(['index'], axis = 'columns', inplace=True)\n",
    "    #Funcion para encontrar Localidades por similitud - Se recupera IdLocalidad y IdProvincia\n",
    "    def verificarLocalidadClientes(row):\n",
    "        ratiomayor=0\n",
    "        for i in range(0,localidades.shape[0]): \n",
    "\n",
    "                Ratio= fuzz.token_sort_ratio(row[\"Localidad\"].lower(), localidades.Localidad[i].lower())\n",
    "                if Ratio>ratiomayor:\n",
    "                        ratiomayor=Ratio\n",
    "                        #venta2.iloc[i,8]\n",
    "                        #miloc= localidades.iloc[i,4]\n",
    "                        miloc=localidades.Localidad[i]\n",
    "                        #id=localidades.iloc[i,3]\n",
    "                        id=localidades.IdLocalidad[i]\n",
    "                        #idprov=localidades.iloc[i,5]\n",
    "                        idprov=localidades.IdProvincia[i]\n",
    "\n",
    "        row[\"Localidad\"]=miloc\n",
    "        row[\"IdLocalidad\"]=id\n",
    "        row[\"IdProvincia\"]=idprov\n",
    "\n",
    "\n",
    "        return row \n",
    "    #Creo DF de clientes con IdLocalidad faltante \n",
    "    clientes_nulos= clientes.loc[clientes['IdLocalidad'].isnull() == True].copy()\n",
    "    #Aplico funcion\n",
    "    clientes_nulos= clientes_nulos.apply(verificarLocalidadClientes,axis=1)\n",
    "    #Borro columnas innecesarias para el merge \n",
    "    clientes_nulos.drop(columns=[\"Latitud\",\"Longitud\"],inplace=True)\n",
    "\n",
    "    #Merge de Clientes con DF Clientes con IDlocalidad Nulos (ya corregido)\n",
    "    clientes = pd.merge(clientes,clientes_nulos, how=\"left\", on=[\"IdCliente\"])\n",
    "\n",
    "    #Completo IdLocalidad en tabla clientes original con 0 para prepararlos para el reemplazo\n",
    "    clientes[\"IdLocalidad_x\"]= clientes[\"IdLocalidad_x\"].fillna(0)\n",
    "    clientes[\"IdProvincia_x\"]= clientes[\"IdProvincia_x\"].fillna(0)\n",
    "    #Realizo reemplazo de IdLocalidad y IdProvincia traidos con el merge\n",
    "    clientes[\"IdLocalidad_x\"]=clientes.apply(lambda x: x[\"IdLocalidad_y\"] if x[\"IdLocalidad_x\"]==0  else x[\"IdLocalidad_x\"], axis=1)\n",
    "    clientes[\"IdProvincia_x\"]=clientes.apply(lambda x: x[\"IdProvincia_y\"] if x[\"IdProvincia_x\"]==0  else x[\"IdProvincia_x\"], axis=1)\n",
    "\n",
    "\n",
    "    #25 Localidades sin IdLocalidad - se lo completa como sin dato\n",
    "    clientes[\"IdLocalidad_x\"]=clientes[\"IdLocalidad_x\"].fillna(0)\n",
    "\n",
    "    #Elimino columnas innecesarias\n",
    "    clientes.drop(['Latitud_y_x','Longitud_y_x','IdDepartamento_x','Provincia_y','Localidad_y', 'Nombre_y_Apellido_y'], axis = 'columns', inplace=True)\n",
    "    clientes.drop(['IdProvincia_y','IdLocalidad_y','IdDepartamento_y','Longitud_y_y','Latitud_y_y', 'Edad_y', 'Telefono_y', 'Domicilio_y'], axis = 'columns', inplace=True)\n",
    "    #Renombro columnas\n",
    "    clientes= clientes.rename(columns= {\"Provincia_x\":\"Provincia\"})\n",
    "    clientes= clientes.rename(columns= {\"Nombre_y_Apellido_x\":\"Nombre_y_Apellido\"})\n",
    "    clientes= clientes.rename(columns= {\"Localidad_x\":\"Localidad\"})\n",
    "    clientes= clientes.rename(columns= {\"Longitud_x\":\"Longitud\"})\n",
    "    clientes= clientes.rename(columns= {\"Latitud_x\":\"Latitud\"})\n",
    "    clientes= clientes.rename(columns= {\"IdLocalidad_x\":\"IdLocalidad\"})\n",
    "    clientes= clientes.rename(columns= {\"IdProvincia_x\":\"IdProvincia\"})\n",
    "    clientes.to_csv (r'C:\\Users\\andre\\OneDrive\\Escritorio\\TP Individual N1\\DS-PI-ProyectoIndividual\\datasetsProcesados\\clientes_dataframe.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "cargadeClientes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROVEEDORES CARGA Y TRATAMIENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "proveedores = pd.read_csv(\"DS-PI-ProyectoIndividual\\Datasets\\Proveedores.csv\",delimiter = ',',encoding = \"ansi\")\n",
    "proveedores.fillna(\"Sin Dato\")\n",
    "proveedores= proveedores.rename(columns= {\"IDProveedor\":\"IdProveedor\", \"Address\":\"Direccion\",\"City\":\"Ciudad\",\"State\":\"Provincia\",\"Country\":\"Pais\",\"departamen\":\"Departamento\"})\n",
    "proveedores.to_csv (r'C:\\Users\\andre\\OneDrive\\Escritorio\\TP Individual N1\\DS-PI-ProyectoIndividual\\datasetsProcesados\\proveedores_dataframe.csv', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ecd682a52e476ba5be570f05223aacbb805de391bd0e8b880b906a66928ac761"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
